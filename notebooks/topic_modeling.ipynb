{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Topic Modeling\n",
        "\n",
        "This notebook performs topic modeling using LDA to identify recurring themes in retail reviews.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim import corpora, models\n",
        "from gensim.models import LdaModel\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/processed_reviews.csv')\n",
        "df = df[df['processed_text'].notna() & (df['processed_text'].str.len() > 0)]\n",
        "print(f\"Loaded {len(df)} processed reviews\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize texts\n",
        "texts = df['processed_text'].tolist()\n",
        "tokenized_texts = [text.split() for text in texts if text and len(text) > 0]\n",
        "\n",
        "# Create dictionary\n",
        "dictionary = corpora.Dictionary(tokenized_texts)\n",
        "dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
        "\n",
        "# Create corpus\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
        "\n",
        "print(f\"Dictionary size: {len(dictionary)}\")\n",
        "print(f\"Corpus size: {len(corpus)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train LDA Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train LDA model\n",
        "num_topics = 5\n",
        "lda_model = LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=num_topics,\n",
        "    random_state=42,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "print(f\"LDA model trained with {num_topics} topics\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Topic Keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "topics = []\n",
        "for idx, topic in lda_model.print_topics(-1, num_words=10):\n",
        "    words = re.findall(r'\"([^\"]+)\"', topic)\n",
        "    topic_dict = {\n",
        "        'topic_id': idx,\n",
        "        'keywords': ', '.join(words[:10]),\n",
        "        'top_words': words[:10]\n",
        "    }\n",
        "    topics.append(topic_dict)\n",
        "\n",
        "topic_df = pd.DataFrame(topics)\n",
        "print(\"Extracted Topics:\")\n",
        "for _, row in topic_df.iterrows():\n",
        "    print(f\"\\nTopic {row['topic_id']}: {row['keywords']}\")\n",
        "\n",
        "topic_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Word Cloud\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create word cloud from all topics\n",
        "all_keywords = ' '.join([' '.join(row['top_words']) for _, row in topic_df.iterrows()])\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_keywords)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Topic Word Cloud', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/visuals/topic_wordcloud.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topic_df.to_csv('../results/topic_keywords.csv', index=False)\n",
        "print(\"Topic keywords saved to ../results/topic_keywords.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
